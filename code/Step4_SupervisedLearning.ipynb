{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters \n",
    " \n",
    "def collection_stats():\n",
    "    # List of documents\n",
    "    documents = reuters.fileids()\n",
    "    print(str(len(documents)) + \" documents\")\n",
    " \n",
    "    train_docs = list(filter(lambda doc: doc.startswith(\"train\"),\n",
    "                        documents))\n",
    "    \n",
    "    test_docs = list(filter(lambda doc: doc.startswith(\"test\"),\n",
    "                       documents))\n",
    "    \n",
    "    # List of categories\n",
    "    categories = reuters.categories()\n",
    "    print(str(len(categories)) + \" categories\")\n",
    "    \n",
    "    print categories\n",
    " \n",
    "    # Documents in a category\n",
    "    #category_docs = reuters.fileids(\"money-supply\")\n",
    " \n",
    "    # Words for a document\n",
    "    # document_id = category_docs[2]\n",
    "    # document_words = reuters.words(category_docs[2])\n",
    "    # print(document_words)  \n",
    " \n",
    "    # Raw document\n",
    "    # print(reuters.raw(document_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10788 documents\n",
      "90 categories\n",
      "[u'acq', u'alum', u'barley', u'bop', u'carcass', u'castor-oil', u'cocoa', u'coconut', u'coconut-oil', u'coffee', u'copper', u'copra-cake', u'corn', u'cotton', u'cotton-oil', u'cpi', u'cpu', u'crude', u'dfl', u'dlr', u'dmk', u'earn', u'fuel', u'gas', u'gnp', u'gold', u'grain', u'groundnut', u'groundnut-oil', u'heat', u'hog', u'housing', u'income', u'instal-debt', u'interest', u'ipi', u'iron-steel', u'jet', u'jobs', u'l-cattle', u'lead', u'lei', u'lin-oil', u'livestock', u'lumber', u'meal-feed', u'money-fx', u'money-supply', u'naphtha', u'nat-gas', u'nickel', u'nkr', u'nzdlr', u'oat', u'oilseed', u'orange', u'palladium', u'palm-oil', u'palmkernel', u'pet-chem', u'platinum', u'potato', u'propane', u'rand', u'rape-oil', u'rapeseed', u'reserves', u'retail', u'rice', u'rubber', u'rye', u'ship', u'silver', u'sorghum', u'soy-meal', u'soy-oil', u'soybean', u'strategic-metal', u'sugar', u'sun-meal', u'sun-oil', u'sunseed', u'tea', u'tin', u'trade', u'veg-oil', u'wheat', u'wpi', u'yen', u'zinc']\n"
     ]
    }
   ],
   "source": [
    "collection_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here I define a tokenizer and stemmer which returns the set of stems in the text that it is passed\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "import re\n",
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# Return the representer, without transforming\n",
    "def tf_idf(docs):\n",
    "    tfidf = TfidfVectorizer(tokenizer=tokenize_and_stem, min_df=0.01,\n",
    "                        max_df=0.90, max_features=3000,\n",
    "                        use_idf=True, sublinear_tf=True,\n",
    "                        norm='l2');\n",
    "    tfidf.fit(docs);\n",
    "    return tfidf;\n",
    "\n",
    "# max_df=0.9, max_features=200000,\n",
    "# min_df=0.01, stop_words='english',\n",
    "# use_idf=True, tokenizer=tokenize_and_stem, \n",
    "# ngram_range=(1,3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize_and_stem, min_df=0.01,\n",
    "                        max_df=0.90, max_features=3000,\n",
    "                        use_idf=True, sublinear_tf=True,\n",
    "                        norm='l2');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_values(doc, representer):\n",
    "    doc_representation = representer.transform([doc])\n",
    "    features = representer.get_feature_names()\n",
    "    return [(features[index], doc_representation[0, index])\n",
    "                 for index in doc_representation.nonzero()[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_docs = []\n",
    "test_docs = []\n",
    "for doc_id in reuters.fileids():\n",
    "    if doc_id.startswith(\"train\"):\n",
    "        train_docs.append(reuters.raw(doc_id))\n",
    "    else:\n",
    "        test_docs.append(reuters.raw(doc_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/14826\n"
     ]
    }
   ],
   "source": [
    "print reuters.fileids()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#representer = tf_idf(train_docs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for doc in test_docs:\n",
    "#    print(feature_values(doc, representer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorised_train_documents = tfidf.fit_transform(train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "X = 1 - cosine_similarity(vectorised_train_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 238\n",
      "Silhouette Coefficient: 0.109\n",
      "Calinski_Harabaz Coefficient: 261.117\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Compute Affinity Propagation\n",
    "af = AffinityPropagation(damping=0.6).fit(X)\n",
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "labels = af.labels_\n",
    "\n",
    "n_clusters_ = len(cluster_centers_indices)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, labels, metric='cosine'))\n",
    "print(\"Calinski_Harabaz Coefficient: %0.3f\"\n",
    "      % metrics.calinski_harabaz_score(X, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# it finds much more clusters than what we have (238 vs 90)\n",
    "# Silhouette Coefficient is very low indicating that clusters overlap a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# selecting only 244 documents at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['training/10708', 'training/6452', 'training/2047', 'test/20533', 'test/20480', 'test/19860', 'training/3997', 'test/19947', 'training/9373', 'training/6399', 'test/16041', 'training/5738', 'training/5640', 'training/9815', 'test/20593', 'training/12433', 'training/4067', 'test/16076', 'training/10760', 'training/10498', 'training/9734', 'test/18313', 'training/3593', 'test/16428', 'training/7659', 'training/11335', 'training/81', 'training/13382', 'training/6239', 'training/5416', 'training/374', 'test/18973', 'training/2159', 'training/5410', 'training/2029', 'training/330', 'training/1708', 'training/8986', 'test/19675', 'test/20052', 'training/2802', 'test/21157', 'test/16041', 'training/745', 'training/5002', 'training/5683', 'training/4049', 'training/14402', 'training/6588', 'training/2622', 'test/16646', 'training/2425', 'test/19005', 'training/12848', 'training/1188', 'training/1949', 'test/20045', 'test/18599', 'training/5543', 'training/1094', 'training/4474', 'training/2691', 'training/859', 'test/16097', 'training/3928', 'test/15132', 'training/2260', 'test/21485', 'training/10136', 'test/16811', 'training/12166', 'test/18807', 'training/11665', 'training/13255', 'test/16247', 'training/10089', 'training/9274', 'test/16759', 'training/9557', 'training/1405', 'training/2862', 'training/3688', 'training/10816', 'training/797', 'training/5682', 'test/15386', 'test/19939', 'training/2186', 'test/20308', 'test/16654', 'training/13184', 'training/2667', 'training/10696', 'training/9511', 'training/13244', 'training/1934', 'training/5565', 'test/16917', 'training/1773', 'test/16213', 'test/19668', 'test/16150', 'training/1084', 'training/9324', 'test/15632', 'test/21259', 'test/17673', 'training/11430', 'training/4474', 'test/17501', 'training/7462', 'training/14220', 'test/15479', 'training/11833', 'test/20838', 'training/3088', 'training/9472', 'training/9737', 'test/20016', 'training/2157', 'training/1545', 'training/516', 'training/7501', 'test/17829', 'training/12914', 'training/10994', 'test/19325', 'training/3853', 'test/14842', 'training/3477', 'training/10536', 'training/10340', 'test/16525', 'training/13005', 'training/5721', 'test/21175', 'test/18223', 'training/5377', 'training/356', 'training/5868', 'training/7166', 'training/9712', 'test/16415', 'training/2593', 'training/12755', 'training/10048', 'test/20654', 'training/2566', 'training/2198', 'test/18479', 'training/5371', 'training/8210', 'training/1910', 'test/15639', 'training/9142', 'training/12743', 'training/8970', 'training/6855', 'training/3954', 'training/14732', 'training/7321', 'training/2909', 'training/12789', 'training/10341', 'training/7381', 'training/9893', 'training/7555', 'training/3163', 'training/8012', 'training/6138', 'training/179', 'training/12040', 'training/7858', 'training/12035', 'training/12574', 'test/16288', 'training/4578', 'test/18337', 'test/16853', 'training/7090', 'training/11843', 'training/11039', 'training/13791', 'training/7047', 'test/19474', 'training/3629', 'test/19684', 'test/15344', 'training/4964', 'training/1147', 'training/4286', 'test/15961', 'training/4033', 'training/14103', 'test/18300', 'training/3701', 'training/5505', 'test/17521', 'training/1300', 'test/15583', 'test/14958', 'training/14524', 'training/7625', 'training/10998', 'training/8131', 'training/8363', 'training/10922', 'test/21496', 'test/15448', 'test/15442', 'training/5203', 'training/11970', 'training/242', 'training/13775', 'test/15420', 'training/8501', 'test/15900', 'training/12550', 'training/9337', 'training/5121', 'training/5398', 'training/290', 'training/6907', 'training/8986', 'training/8750', 'training/10219', 'training/9284', 'training/11102', 'training/3247', 'training/10114', 'test/20376', 'test/14957', 'training/529', 'test/15031', 'training/8287', 'test/16835', 'training/13834', 'training/14751', 'training/4345', 'test/16149', 'training/12836', 'training/5947', 'training/1502', 'training/4953', 'training/1568', 'training/1541', 'test/17516', 'training/1971', 'training/189', 'training/2182']\n"
     ]
    }
   ],
   "source": [
    "rndm_reuters_fileids_train = []\n",
    "randint_train = []\n",
    "#print random.uniform(0, len(rndm_reuters_fileids))\n",
    "import numpy as np\n",
    "for i in range(0,250):\n",
    "    randint = np.random.randint(0,len(reuters.fileids()))\n",
    "    randint_train.append(randint)\n",
    "    rndm_reuters_fileids_train.append(reuters.fileids()[randint])\n",
    "print rndm_reuters_fileids_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test/21401', 'test/20981', 'test/20769', 'training/9497', 'training/13539', 'training/7266', 'test/16675', 'test/21260', 'test/18604', 'test/15866', 'training/8605', 'test/15778', 'training/2919', 'training/12344', 'training/3695', 'training/12222', 'training/5458', 'training/2896', 'training/8200', 'test/20652', 'training/1528', 'training/7558', 'test/18570', 'training/9356', 'training/10106', 'test/20730', 'test/16493', 'test/19946', 'test/21248', 'test/14985', 'training/7113', 'training/14099', 'training/6093', 'test/16175', 'training/9511', 'test/18851', 'test/15483', 'training/5690', 'training/5477', 'test/15808', 'training/3713', 'training/10973', 'training/8027', 'training/1047', 'training/12258', 'training/9893', 'test/17643', 'training/4152', 'training/4831', 'test/15914', 'test/14912', 'training/8478', 'training/7634', 'test/16357', 'training/4759', 'training/7873', 'training/11751', 'training/14315', 'training/6442', 'training/3620', 'training/10404', 'training/5411', 'training/1209', 'test/19982', 'training/11575', 'test/21181', 'training/2580', 'training/9654', 'training/10080', 'training/3370', 'training/7814', 'training/7752', 'training/4071', 'training/8288', 'training/4459', 'test/15949', 'training/521', 'training/9612', 'training/9428', 'test/18467']\n"
     ]
    }
   ],
   "source": [
    "rndm_reuters_fileids_test = []\n",
    "randint_test = []\n",
    "#print random.uniform(0, len(rndm_reuters_fileids))\n",
    "import numpy as np\n",
    "for i in range(0,80):\n",
    "    randint = np.random.randint(0,len(reuters.fileids()))\n",
    "    randint_test.append(randint)\n",
    "    rndm_reuters_fileids_test.append(reuters.fileids()[randint])\n",
    "print rndm_reuters_fileids_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_docs_160 = []\n",
    "test_docs_80 = []\n",
    "for doc_id in rndm_reuters_fileids_train:\n",
    "    train_docs_160.append(reuters.raw(doc_id))\n",
    "for doc_id in rndm_reuters_fileids_test:\n",
    "    test_docs_80.append(reuters.raw(doc_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorised_test_documents_80 = tfidf.transform(test_docs_80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorised_train_documents_160 = tfidf.transform(train_docs_160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "X = 1 - cosine_similarity(vectorised_train_documents_160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Damping: ', 0.5)\n",
      "Estimated number of clusters: 30\n",
      "Silhouette Coefficient: 0.180\n",
      "Calinski_Harabaz Coefficient: 22.344\n",
      "('Damping: ', 0.55000000000000004)\n",
      "Estimated number of clusters: 32\n",
      "Silhouette Coefficient: 0.180\n",
      "Calinski_Harabaz Coefficient: 21.527\n",
      "('Damping: ', 0.60000000000000009)\n",
      "Estimated number of clusters: 31\n",
      "Silhouette Coefficient: 0.179\n",
      "Calinski_Harabaz Coefficient: 21.882\n",
      "('Damping: ', 0.65000000000000013)\n",
      "Estimated number of clusters: 31\n",
      "Silhouette Coefficient: 0.179\n",
      "Calinski_Harabaz Coefficient: 21.965\n",
      "('Damping: ', 0.70000000000000018)\n",
      "Estimated number of clusters: 31\n",
      "Silhouette Coefficient: 0.179\n",
      "Calinski_Harabaz Coefficient: 21.965\n",
      "('Damping: ', 0.75000000000000022)\n",
      "Estimated number of clusters: 31\n",
      "Silhouette Coefficient: 0.179\n",
      "Calinski_Harabaz Coefficient: 21.965\n",
      "('Damping: ', 0.80000000000000027)\n",
      "Estimated number of clusters: 31\n",
      "Silhouette Coefficient: 0.179\n",
      "Calinski_Harabaz Coefficient: 21.965\n",
      "('Damping: ', 0.85000000000000031)\n",
      "Estimated number of clusters: 28\n",
      "Silhouette Coefficient: 0.151\n",
      "Calinski_Harabaz Coefficient: 23.004\n",
      "('Damping: ', 0.90000000000000036)\n",
      "Estimated number of clusters: 28\n",
      "Silhouette Coefficient: 0.151\n",
      "Calinski_Harabaz Coefficient: 23.004\n",
      "('Damping: ', 0.9500000000000004)\n",
      "Estimated number of clusters: 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-16492826a944>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Estimated number of clusters: %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn_clusters_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     print(\"Silhouette Coefficient: %0.3f\"\n\u001b[0;32m---> 14\u001b[0;31m         % metrics.silhouette_score(X, labels, metric='cosine'))\n\u001b[0m\u001b[1;32m     15\u001b[0m     print(\"Calinski_Harabaz Coefficient: %0.3f\"\n\u001b[1;32m     16\u001b[0m         % metrics.calinski_harabaz_score(X, labels))\n",
      "\u001b[0;32m/Users/marcello/anaconda/lib/python2.7/site-packages/sklearn/metrics/cluster/unsupervised.pyc\u001b[0m in \u001b[0;36msilhouette_score\u001b[0;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msilhouette_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcello/anaconda/lib/python2.7/site-packages/sklearn/metrics/cluster/unsupervised.pyc\u001b[0m in \u001b[0;36msilhouette_samples\u001b[0;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mcheck_number_of_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marcello/anaconda/lib/python2.7/site-packages/sklearn/metrics/cluster/unsupervised.pyc\u001b[0m in \u001b[0;36mcheck_number_of_labels\u001b[0;34m(n_labels, n_samples)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_labels\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         raise ValueError(\"Number of labels is %d. Valid values are 2 \"\n\u001b[0;32m---> 20\u001b[0;31m                          \"to n_samples - 1 (inclusive)\" % n_labels)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Compute Affinity Propagation\n",
    "for damp in np.arange(0.5,1.0,0.05):\n",
    "    af = AffinityPropagation(damping=damp).fit(X)\n",
    "    cluster_centers_indices = af.cluster_centers_indices_\n",
    "    labels = af.labels_\n",
    "\n",
    "    n_clusters_ = len(cluster_centers_indices)\n",
    "    print('Damping: ',damp)\n",
    "    print('Estimated number of clusters: %d' % n_clusters_)\n",
    "    print(\"Silhouette Coefficient: %0.3f\"\n",
    "        % metrics.silhouette_score(X, labels, metric='cosine'))\n",
    "    print(\"Calinski_Harabaz Coefficient: %0.3f\"\n",
    "        % metrics.calinski_harabaz_score(X, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorised_test_documents = tfidf.transform(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#List of document ids\n",
    "documents = reuters.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_docs_id = list(filter(lambda doc: doc.startswith(\"train\"),\n",
    "                            documents))\n",
    "test_docs_id = list(filter(lambda doc: doc.startswith(\"test\"),\n",
    "                           documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform multilabel labels\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "train_labels = mlb.fit_transform([reuters.categories(doc_id)\n",
    "                                  for doc_id in train_docs_id])\n",
    "test_labels = mlb.transform([reuters.categories(doc_id)\n",
    "                             for doc_id in test_docs_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
